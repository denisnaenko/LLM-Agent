import cv2
import numpy as np
from ultralytics import YOLO
import os
import asyncio

async def crop_object_async(image_path, 
                            class_to_crop="makeup-composition", 
                            output_dir="cropped_images", 
                            use_contour=False):
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–µ–∑–∫–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    """
    loop = asyncio.get_event_loop()

    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
    return await loop.run_in_executor(
        None,
        crop_object,
        image_path,
        class_to_crop,
        output_dir,
        use_contour
    )

def crop_object(image_path, 
                class_to_crop="makeup-composition", 
                output_dir="cropped_images", 
                use_contour=False):
    """
    –û–±—Ä–µ–∑–∞–µ—Ç –æ–±—ä–µ–∫—Ç—ã –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ bounding box –∏–ª–∏ –∫–æ–Ω—Ç—É—Ä–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    –∏ –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å bbox.

    Args:
        image_path (str): –ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é.
        class_to_crop (str): –ù–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –æ–±—ä–µ–∫—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –æ–±—Ä–µ–∑–∞—Ç—å.
        output_dir (str): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–µ–∑–∞–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
        use_contour (bool): True –¥–ª—è –æ–±—Ä–µ–∑–∫–∏ –ø–æ –∫–æ–Ω—Ç—É—Ä—É, False –¥–ª—è –æ–±—Ä–µ–∑–∫–∏ –ø–æ bounding box.

    Returns:
        str: –°–æ–æ–±—â–µ–Ω–∏–µ –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –æ–±—Ä–µ–∑–∫–∏.
    """
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLO
    model_path = r"models/trained_model.pt"
    model = YOLO(model_path)

    # –ß—Ç–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image = cv2.imread(image_path)
    if image is None:
        print(f"–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_path}")
        return "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."

    # –ö–æ–ø–∏—è –¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤
    original_image_with_boxes = image.copy()

    # –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏
    results = model(image)

    cropped_image_paths = []
    object_count = 1

    # –ü—Ä–æ—Ö–æ–¥ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –¥–µ—Ç–µ–∫—Ü–∏–∏
    for result in results:
        boxes = result.boxes.xyxy.cpu().numpy().astype(int)
        confs = result.boxes.conf.cpu().numpy()
        classes = result.boxes.cls.cpu().numpy().astype(int)
        masks = result.masks  # –ü–æ–ª—É—á–∞–µ–º –º–∞—Å–∫–∏, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–±—Ä–µ–∑–∞–µ–º –ø–æ bbox

        for i, (xyxy, conf, class_id) in enumerate(zip(boxes, confs, classes)):
            class_name = model.names[int(class_id)]

            # –ü—Ä–æ–≤–µ—Ä–∫–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–ª–∞—Å—Å –Ω—É–∂–Ω–æ–º—É
            if class_name == class_to_crop:
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bounding box
                x_min, y_min, x_max, y_max = int(xyxy[0]), int(xyxy[1]), int(xyxy[2]), int(xyxy[3])

                # –†–∏—Å—É–µ–º bounding box –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
                cv2.rectangle(original_image_with_boxes, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                if use_contour:
                    # –û–±—Ä–µ–∑–∫–∞ –ø–æ –∫–æ–Ω—Ç—É—Ä—É
                    mask = masks[i].cpu().numpy().astype(np.uint8)
                    mask = cv2.resize(mask, (x_max - x_min, y_max - y_min), interpolation=cv2.INTER_NEAREST)

                    full_mask = np.zeros(image.shape[:2], dtype=np.uint8)
                    full_mask[y_min:y_max, x_min:x_max] = mask

                    contours, _ = cv2.findContours(full_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    if contours:
                        max_contour = max(contours, key=cv2.contourArea)
                        x, y, w, h = cv2.boundingRect(max_contour)
                        cropped_image = image[y:y + h, x:x + w].copy()
                else:
                    cropped_image = image[y_min:y_max, x_min:x_max].copy()

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–µ–∑–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                output_path = os.path.join(output_dir, f"cropped_object_{object_count}.jpg")
                cv2.imwrite(output_path, cropped_image)
                cropped_image_paths.append(output_path)
                object_count += 1

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å bbox
    original_output_path = os.path.join(output_dir, "original_image_with_boxes.jpg")
    cv2.imwrite(original_output_path, original_image_with_boxes)

    # –í–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    if not cropped_image_paths:
        return False, (
            "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏.\n\n"
            "–í–æ–∑–º–æ–∂–Ω–æ, —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º —Ä–∞–∑–º—ã—Ç—ã–π, –ø–ª–æ—Ö–æ –æ—Å–≤–µ—â—ë–Ω–Ω—ã–π –∏–ª–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è —Å–¥–µ–ª–∞–Ω–∞ –ø–æ–¥ —É–≥–ª–æ–º. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\n\n"
            "‚Ä¢ –°—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–π—Ç–µ —Ç–µ–∫—Å—Ç –ø—Ä–∏ —Ö–æ—Ä–æ—à–µ–º –æ—Å–≤–µ—â–µ–Ω–∏–∏‚òÄ.\n\n"
            "‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤–µ—Å—å —Ç–µ–∫—Å—Ç –≤–∏–¥–µ–Ω –Ω–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏üìú.\n\n"
            "‚Ä¢ –î–µ—Ä–∂–∏—Ç–µ –∫–∞–º–µ—Ä—É –ø—Ä—è–º–æ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∏—Å–∫–∞–∂–µ–Ω–∏–πü§≥.\n\n"
        )
    
    return True, "‚úÖ –§–æ—Ç–æ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ! –ü—Ä–∏—Å—Ç—É–ø–∞—é –∫ –∞–Ω–∞–ª–∏–∑—É...üìù"
